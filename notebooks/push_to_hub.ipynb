{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/raki/raki-projects/t5-tuning\n",
      "/data/home/raki/raki-projects/t5-tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raki/raki-projects/t5-tuning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if 'has_changed_dir' not in globals():\n",
    "    repo_path = os.path.abspath(os.path.join('..'))\n",
    "    \n",
    "    if repo_path not in sys.path:\n",
    "        sys.path.append(repo_path)\n",
    "    \n",
    "    os.chdir(repo_path)\n",
    "    \n",
    "    globals()['has_changed_dir'] = True\n",
    "    print(repo_path)\n",
    "    print(os.getcwd())\n",
    "\n",
    "\n",
    "# from typing import Optional, Union\n",
    "\n",
    "# import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from src.train_model import LightningModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "/home/raki/raki-projects/t5-tuning/.venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "final_model_path = \"models/mt5-base-new/converted\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(final_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(final_model_path)\n",
    "lightning_model = LightningModel(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Когда римские воины и вожди, а также главные священнослужители и блюстители Закона пришли в Иудею, они дали ему вооружённые оружие, браслеты и серьги.']\n"
     ]
    }
   ],
   "source": [
    "sentence: str = \"Римдин аскерар ва гьакӀни чӀехи хахамрини  фарисейри ракъурнавай нуькерар Ягьуд галаз багъдиз атана. Абурув виридав яракьар, чирагъар ва шемгьалар гвай.\"\n",
    "\n",
    "translation = lightning_model.predict(sentence, prefix = \"translate Lezghian to Russian: \")\n",
    "\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 2.33G/2.33G [01:14<00:00, 31.2MB/s]  \n",
      "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]\n",
      "spiece.model: 100%|██████████| 4.31M/4.31M [00:01<00:00, 3.66MB/s]\n",
      "\n",
      "tokenizer.json: 100%|██████████| 16.4M/16.4M [00:01<00:00, 8.81MB/s]\n",
      "\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/leks-forever/mt5-base/commit/25f011e52569e89e5ace43ec728e75a6960658b5', commit_message='Upload tokenizer', commit_description='', oid='25f011e52569e89e5ace43ec728e75a6960658b5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/leks-forever/mt5-base', endpoint='https://huggingface.co', repo_type='model', repo_id='leks-forever/mt5-base'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YOUR_TOKEN = \"Your access token here\" # noqa: S105\n",
    "\n",
    "model.push_to_hub(\"leks-forever/mt5-base\", token = YOUR_TOKEN)\n",
    "tokenizer.push_to_hub(\"leks-forever/mt5-base\", token  = YOUR_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raki/raki-projects/t5-tuning/.venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"leks-forever/mt5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"leks-forever/mt5-base\")\n",
    "lightning_model = LightningModel(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Когда римские воины и вожди, а также главные священнослужители и блюстители Закона пришли в Иудею, они дали ему вооружённые оружие, браслеты и серьги.']\n"
     ]
    }
   ],
   "source": [
    "sentence: str = \"Римдин аскерар ва гьакӀни чӀехи хахамрини  фарисейри ракъурнавай нуькерар Ягьуд галаз багъдиз атана. Абурув виридав яракьар, чирагъар ва шемгьалар гвай.\"\n",
    "\n",
    "translation = lightning_model.predict(sentence, prefix = \"translate Lezghian to Russian: \")\n",
    "\n",
    "print(translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
